{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b46385-77c8-470b-86e4-2c5ce2e5bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4d7fe-aa19-4981-81f9-5e960428ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting samples for Alishba. Press 'q' to stop early.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def generate_dataset(user_id, user_name, samples=50, save_dir=\"data\"):\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    if face_classifier.empty():\n",
    "        raise Exception(\"Error: Haar cascade not loaded.\")\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Train a temporary recognizer on existing dataset to detect duplicates\n",
    "    existing_faces = []\n",
    "    existing_ids = []\n",
    "    for file in os.listdir(save_dir):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            path = os.path.join(save_dir, file)\n",
    "            img = Image.open(path).convert('L')\n",
    "            img_np = np.array(img, 'uint8')\n",
    "            id_in_file = int(file.split(\".\")[1])\n",
    "            existing_faces.append(img_np)\n",
    "            existing_ids.append(id_in_file)\n",
    "    \n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    if len(existing_faces) > 0:\n",
    "        recognizer.train(existing_faces, np.array(existing_ids))\n",
    "    else:\n",
    "        recognizer = None  # No previous faces yet\n",
    "\n",
    "    def face_cropped(img):\n",
    "        if img is None:\n",
    "            return None\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(faces) == 0:\n",
    "            return None\n",
    "        for (x, y, w, h) in faces:\n",
    "            return img[y:y+h, x:x+w], (x, y, w, h)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Error: Could not open webcam.\")\n",
    "\n",
    "    img_id = 0\n",
    "    print(f\"Collecting samples for {user_name}. Press 'q' to stop early.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame from webcam.\")\n",
    "            break\n",
    "\n",
    "        result = face_cropped(frame)\n",
    "        if result is not None:\n",
    "            face, (x, y, w, h) = result\n",
    "            gray_face = cv2.cvtColor(cv2.resize(face, (200, 200)), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Check if face already exists in dataset\n",
    "            if recognizer is not None:\n",
    "                try:\n",
    "                    pred_id, conf = recognizer.predict(gray_face)\n",
    "                    confidence = int(100 * (1 - conf / 300))\n",
    "                    if confidence > 95:  # Face already exists\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,0,255), 2)\n",
    "                        cv2.putText(frame, f\"{user_name} cannot take pics! Already exists\",\n",
    "                                    (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
    "                        cv2.imshow(\"Capturing Faces\", frame)\n",
    "                        cv2.waitKey(2000)  # show message for 2 sec\n",
    "                        break\n",
    "                except:\n",
    "                    pass  # No match found\n",
    "\n",
    "            # Save new image\n",
    "            img_id += 1\n",
    "            file_name_path = f\"{save_dir}/{user_name}.{user_id}.{img_id}.jpg\"\n",
    "            cv2.imwrite(file_name_path, gray_face)\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{user_name} ({img_id}/{samples})\", (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Capturing Faces\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') or img_id >= samples:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Collected {img_id} samples for {user_name} successfully!\")\n",
    "\n",
    "# Example usage\n",
    "generate_dataset(user_id=1, user_name=\"Alishba\", samples=50)\n",
    "generate_dataset(user_id=2, user_name=\"Kinza\", samples=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df1de5-6fa6-4eab-b9c1-aca758ef8571",
   "metadata": {},
   "source": [
    "Train the classifier and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a184c8-2d56-420c-b995-301555e1d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image #pip install pillow\n",
    "import numpy as np    # pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8f1d5d7-0ef7-44bc-bb3d-6d6dc515d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! Classifier saved as 'classifier.xml'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def train_classifier(data_dir=\"data\"):\n",
    "    \"\"\"\n",
    "    Train LBPH face recognizer on images stored in `data_dir`.\n",
    "\n",
    "    Each image file should follow the format: name.user_id.sample_id.jpg\n",
    "    Example: Alishba.1.1.jpg\n",
    "    \"\"\"\n",
    "    faces = []\n",
    "    ids = []\n",
    "\n",
    "    image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "    if len(image_files) == 0:\n",
    "        print(\"No images found in the data directory.\")\n",
    "        return\n",
    "\n",
    "    for image_path in image_files:\n",
    "        try:\n",
    "            # Convert to grayscale\n",
    "            img = Image.open(image_path).convert('L')\n",
    "            img_np = np.array(img, 'uint8')\n",
    "\n",
    "            # Extract user_id from filename\n",
    "            filename = os.path.split(image_path)[1]  # e.g., \"Alishba.1.1.jpg\"\n",
    "            user_id = int(filename.split(\".\")[1])\n",
    "\n",
    "            faces.append(img_np)\n",
    "            ids.append(user_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {image_path}: {e}\")\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(\"No valid images to train.\")\n",
    "        return\n",
    "\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    # Create LBPH face recognizer\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.train(faces, ids)\n",
    "    clf.write(\"classifier.xml\")\n",
    "    print(\"Training complete! Classifier saved as 'classifier.xml'.\")\n",
    "\n",
    "# Train the classifier using all images in the 'data' folder\n",
    "train_classifier(\"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc38c974-2218-4e71-8fd0-15e768ad43c8",
   "metadata": {},
   "source": [
    "Face detection/recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44d77909-1726-4b8c-8143-c9d358ead3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edd1dc3a-ae85-47bc-9cb2-4210b01f244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# ------------------- Mapping IDs to Names ------------------- #\n",
    "id_to_name = {\n",
    "    1: \"Alishba\",\n",
    "    2: \"Kinza\",\n",
    "    3: \"Maryam\",\n",
    "}\n",
    "\n",
    "# ------------------- Function to Draw Boundaries ------------------- #\n",
    "def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, clf, id_to_name):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around face\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        \n",
    "        # Predict ID using trained classifier\n",
    "        id, pred = clf.predict(gray_img[y:y + h, x:x + w])\n",
    "        confidence = int(100 * (1 - pred / 300))\n",
    "        \n",
    "        # Display name or UNAUTHORIZED\n",
    "        if confidence > 80:\n",
    "            name = id_to_name.get(id, \"Unknown\")\n",
    "            cv2.putText(img, f\"{name} ({confidence}%)\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "        else:\n",
    "            cv2.putText(img, \"UNAUTHORIZED\", (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# ------------------- Load Haar Cascade & Classifier ------------------- #\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "if faceCascade.empty():\n",
    "    raise Exception(\"Error: Could not load Haar cascade xml file.\")\n",
    "\n",
    "clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "clf.read(\"classifier.xml\")\n",
    "\n",
    "# ------------------- Open Webcam ------------------- #\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "if not video_capture.isOpened():\n",
    "    raise Exception(\"Error: Could not open webcam.\")\n",
    "\n",
    "# ------------------- Real-Time Face Recognition ------------------- #\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame from webcam.\")\n",
    "        break\n",
    "\n",
    "    frame = draw_boundary(frame, faceCascade, 1.3, 5, (0, 255, 0), clf, id_to_name)\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9f651-4417-49fb-9f06-e447389d14e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
